{
 "cells": [
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "---\n",
    "title: \"Data Science Design Pattern for Student Drop Out\"\n",
    "author: \"Microsoft\"\n",
    "output: \n",
    "    rmarkdown::html_vignette:\n",
    "        toc: true\n",
    "\n",
    "vignette: >\n",
    "  %\\VignetteIndexEntry{Vignette Title}\n",
    "  %\\VignetteEngine{knitr::rmarkdown}\n",
    "  %\\VignetteEncoding{UTF-8}\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "knitr::opts_chunk$set(fig.width = 6,\n",
    "                      fig.height = 4,\n",
    "                      fig.align='center',\n",
    "                      dev = \"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Introducation\n",
    "\n",
    "Welcome to the Data Science Design Pattern for Student Drop Out. This pattern provides a starting point for the data scientist exploring a new dataset. By no means is it the end point of the data science journey. The pattern is under regular revision and improvement and is provided as is.\n",
    "\n",
    "We now begin with the task of preparing our data for building models using R. \n",
    "\n",
    "# Pre-configuration\n",
    "\n",
    "We load the R packages required for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# R SETUP\n",
    "# Load required packages from local library into R.\n",
    "\n",
    "library(rattle)       # The normVarNames().\n",
    "library(readr)        # Modern and efficient data reader.\n",
    "library(dplyr)        # Wrangling: tbl_df(), group_by(), print(), glimpse().\n",
    "library(magrittr)     # Pipe operator %>% %<>% %T>% equals().\n",
    "library(lubridate)    # Dates and time.\n",
    "library(tidyr)        # Tidy the dataset: gather().\n",
    "library(stringi)      # String concat operator %s+%.\n",
    "library(stringr)      # String manipulation: str_replace().\n",
    "library(randomForest) # Impute missing values with na.roughfix()\n",
    "library(ggplot2)      # Visualise data.\n",
    "library(tibble)       # Table data frame: rownames_to_column()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "Let's define some utility functions which simplify the coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Useful utility functions.\n",
    "\n",
    "echo <- function(x, big.mark=\",\", ...)\n",
    "{\n",
    "  format(x, big.mark=big.mark, ...) %>% cat(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 1.1: Load - Dataset\n",
    "\n",
    "We use the studentDropIndia dataset simulated from student data in UCI repository and an India State Government to illustrate our data preparation. Often though we will be loading the dataset from a CSV file and so we illustrate that step first. We begin by identifying the path to the CSV file we wish to load - in this case we load it from a local directory. Then it is a simple matter of reading the data into the memory of the computer, referring to it as variable studentDropIndia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DATA INGESTION\n",
    "\n",
    "# Identify the source location of the dataset.\n",
    "\n",
    "dspath <- \"../../Data/studentDropIndia_20161215.csv\"\n",
    "\n",
    "# Ingest the dataset.\n",
    "\n",
    "studentDropIndia <- read_csv(file=dspath)\n",
    "\n",
    "# Name the dataset.\n",
    "\n",
    "dsname <- \"studentDropIndia\""
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 1.2: Load - Generic Variables\n",
    "\n",
    "Next, we will store the variable studentDropIndia to a generic variable ds and take a glimpse of it. This will make the following steps somewhat generic and often we can just load a different dataset into ds and these steps can simply be re-run without change. Finally, we save the variable studentDropIndia into a data folder as a .RData file and reload it for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for usage with our template.\n",
    "\n",
    "ds <- get(dsname)\n",
    "glimpse(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Save the dataset to disk as a binary backup if needed.\n",
    "\n",
    "fpath <- \"data\"\n",
    "fname <- file.path(fpath, dsname %s+% \".RData\")\n",
    "if (! dir.exists(fpath)) dir.create(fpath)\n",
    "save(studentDropIndia, file=fname)\n",
    "\n",
    "# Remove the original dataset to save on memory.\n",
    "\n",
    "rm(studentDropIndia)\n",
    "\n",
    "# Test the loading of the saved dataset and then cleanup.\n",
    "\n",
    "load(fname) %>% print()\n",
    "\n",
    "rm(studentDropIndia)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.1: Review - Dataset\n",
    "\n",
    "We check the dimension and variable information of the dataset. There are 19,100 rows and 15 columns totally in the dataset, which includes variables showing information about student demographic, school attributes, teacher skills and school record in various data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DATA OBSERVATION\n",
    "\n",
    "# Basic size information.\n",
    "\n",
    "nrow(ds) %>% echo()\n",
    "ncol(ds) %>% echo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# A glimpse into the dataset.\n",
    "\n",
    "glimpse(ds)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.2: Review - Meta Data Cleansing\n",
    "\n",
    "Then we review the variable names and convert them into a standard form using the function normVarNames() from rattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DATA WRANGLING\n",
    "\n",
    "# Review the variables to optionally normalise their names.\n",
    "\n",
    "names(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Normalise the variable names.\n",
    "\n",
    "names(ds) %<>% normVarNames() %T>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review the dataset.\n",
    "\n",
    "glimpse(ds)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.3: Review - Observations\n",
    "\n",
    "Once we have normalized the variable names, the next step is to understand the shape of the dataset. A first look at the sample observations by using head(), tail(), and sample_n() give us an initial understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review the first few observations.\n",
    "\n",
    "head(ds) %>% print.data.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review the last few observations.\n",
    "\n",
    "tail(ds) %>% print.data.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review a random sample of observations.\n",
    "\n",
    "sample_n(ds, size=6) %>% print.data.frame()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.4: Review - Summary\n",
    "\n",
    "Next, we use summary() to preview the distributions of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Traditional dataset summary to get started.\n",
    "\n",
    "summary(ds)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.5: Review - Data Formats\n",
    "\n",
    "Except for the generic data wrangling, we now do data wrangling customized for studentDropIndia. For example, we may need to correct the format of some of the variables in our dataset. We might first check the data type of each variable. Noting that there are categorical variables in the formats of character and integer, we may like to convert them to factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# studentDropIndia data wrangling.\n",
    "\n",
    "# How many schools are represented in the dataset? (Why we need to know this)\n",
    "\n",
    "ds$school_id %>% \n",
    "  unique() %>%\n",
    "  length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Check the class of all the variables.\n",
    "\n",
    "ds %>% sapply(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Select all the character variables.\n",
    "\n",
    "ds %>%\n",
    "  sapply(is.character) %>%\n",
    "  which(useNames=TRUE) %>%\n",
    "  names() %T>% \n",
    "  print() ->\n",
    "vnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review the values of the variables.\n",
    "\n",
    "ds[vnames] %>%\n",
    "  sapply(as.factor) %>%\n",
    "  summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Choose to convert these variables from character to factor.\n",
    "\n",
    "vnames %<>% setdiff(c(\"student_id\")) %T>% print()\n",
    "\n",
    "ds[vnames] %<>% \n",
    "  lapply(factor) %>% \n",
    "  data.frame() %>% \n",
    "  tbl_df()\n",
    "\n",
    "# Confirm they are now factors.\n",
    "\n",
    "ds[vnames] %>% sapply(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Select all the logical variables.\n",
    "\n",
    "ds %>%\n",
    "  sapply(is.logical) %>%\n",
    "  which(useNames=TRUE) %>%\n",
    "  names() %T>% \n",
    "  print() ->\n",
    "vnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Decide to convert these variables from logical to factor.\n",
    "\n",
    "ds[vnames] %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "ds[vnames] %<>% \n",
    "  lapply(factor) %>% \n",
    "  data.frame() %>% \n",
    "  tbl_df() %T>%\n",
    "  {head(.) %>% print()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Review the distribution of observations across levels.\n",
    "\n",
    "ds[, sapply(ds, is.factor)] %>% sapply(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Note the remaining variables to be dealt with.\n",
    "\n",
    "sapply(ds, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "vnames <- c(\"english_marks\", \"science_marks\", \"mathematics_marks\") \n",
    "\n",
    "# Review the values.\n",
    "\n",
    "head(ds[vnames])\n",
    "sample_n(ds[vnames], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Check the current class of the variables.\n",
    "\n",
    "ds[vnames] %>% sapply(class)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 2.6: Review - Variable Roles\n",
    "\n",
    "We are now in a position to identify the roles played by the variables within the dataset. We assign the variable continue_drop which we are going to predict to be our target variable and put it in front of all. We treat the varaibles student_id, and school_id as observation identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Variable Roles\n",
    "\n",
    "# Note the available variables.\n",
    "\n",
    "vars <- names(ds) %T>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Note the target variable.\n",
    "\n",
    "target <- \"continue_drop\"\n",
    "\n",
    "# Place the target variable at the beginning of the vars.\n",
    "\n",
    "vars <- c(target, vars) %>% unique() %T>% print()\n",
    "\n",
    "# Note any identifiers.\n",
    "\n",
    "id <- c(\"student_id\", \"school_id\")"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.1: Clean - Ignore IDs, Outputs, Missing\n",
    "\n",
    "## IDs and Outputs \n",
    "\n",
    "We will want to ignore some variables that are irrelevant or inappropriate for modelling as normal predictors. We start with the identifiers and the risk variable (there is no risk variable in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Generic data wrangling.\n",
    "\n",
    "# Initialise ignored variables: identifiers and risk.\n",
    "\n",
    "ignore <- union(id, if (exists(\"risk\")) risk) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "We might also identify any variable that has a unique value for every observation. These are sometimes identifiers as well and if so are candidates for ignoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Heuristic for candidate identifiers to possibly ignore. \n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(function(x) x %>% unique() %>% length()) %>%\n",
    "  equals(nrow(ds)) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "ids\n",
    "\n",
    "# Add them if any to the variables to be ignored for modelling.\n",
    "\n",
    "ignore <- union(ignore, ids) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "## All Missing\n",
    "\n",
    "We then remove any variable where all of the values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify variables with only missing values.\n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(function(x) x %>% is.na %>% sum) %>%\n",
    "  equals(nrow(ds)) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "missing\n",
    "\n",
    "# Add them if any to the variables to be ignored for modelling.\n",
    "\n",
    "ignore <- union(ignore, missing) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "## Many Missing\n",
    "\n",
    "Perhaps we also want to ignore variables with more than 70% of the values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify a threshold above which proportion missing is fatal.\n",
    "\n",
    "missing.threshold <- 0.7\n",
    "\n",
    "# Identify variables that are mostly missing.\n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(function(x) x %>% is.na() %>% sum()) %>%\n",
    "  '>'(missing.threshold*nrow(ds)) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "mostly\n",
    "\n",
    "# Add them if any to the variables to be ignored for modelling.\n",
    "\n",
    "ignore <- union(ignore, mostly) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.2: Clean - Ignore MultiLevel, Constants\n",
    "\n",
    "## Too Many Levels\n",
    "\n",
    "We might also want to ignore variables with too many levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify a threshold above which we have too many levels.\n",
    "\n",
    "levels.threshold <- 20\n",
    "\n",
    "# Identify variables that have too many levels.\n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(is.factor) %>%\n",
    "  which() %>%\n",
    "  names() %>%\n",
    "  sapply(function(x) ds %>% extract2(x) %>% levels() %>% length()) %>%\n",
    "  '>='(levels.threshold) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "too.many\n",
    "\n",
    "# Add them if any to the variables to be ignored for modelling.\n",
    "\n",
    "ignore <- union(ignore, too.many) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "## Constants\n",
    "\n",
    "We ingore variables with constant values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify variables that have a single value.\n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(function(x) all(x == x[1L])) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "constants \n",
    "\n",
    "# Add them if any to the variables to be ignored for modelling.\n",
    "\n",
    "ignore <- union(ignore, constants) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.3: Clean - Ignore Correlated Varaibles\n",
    "\n",
    "Within all the numeric varaibles, we can identify pairs where we want to keep one but not the other, because they are highly correlated. We will select them manually since it is a judgement call. Normally we might limit the removals to those correlations that are 0.95 or more. In this case, there does not exist a collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Note which variables are numeric.\n",
    "\n",
    "vars %>%\n",
    "  setdiff(ignore) %>%\n",
    "  '['(ds, .) %>%\n",
    "  sapply(is.numeric) %>% \n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "numc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# For the numeric variables generate a table of correlations\n",
    "\n",
    "ds[numc] %>%\n",
    "  cor(use=\"complete.obs\") %>%\n",
    "  ifelse(upper.tri(., diag=TRUE), NA, .) %>% \n",
    "  abs %>% \n",
    "  data.frame %>%\n",
    "  tbl_df %>%\n",
    "  set_colnames(numc) %>%\n",
    "  mutate(var1=numc) %>% \n",
    "  gather(var2, cor, -var1) %>% \n",
    "  na.omit %>%\n",
    "  arrange(-abs(cor)) %T>%\n",
    "  print() ->\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Any variables could be removed because highly correlated?\n",
    "\n",
    "ignore <- union(ignore, NULL) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.4: Clean - Remove the Ignored Variables\n",
    "\n",
    "Once we have identified the variables to ignore, we remove them from our list of variables to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Check the number of variables currently.\n",
    "\n",
    "length(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the variables to ignore.\n",
    "\n",
    "vars <- setdiff(vars, ignore) %T>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm they are now ignored.\n",
    "\n",
    "length(vars)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.5: Clean - Feature Selection\n",
    "\n",
    "The FSelector (Romanski, 2013) package provides functions to identify subsets of variables that might be more effective for modelling. For example, we can use correlation search function cfs() to identify key variables and thus decide which variables to retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE,",
     "eval": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Variable Selection\n",
    "\n",
    "# Formula for modelling.\n",
    "\n",
    "form <- formula(target %s+% \" ~ .\") %T>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Use correlation search to identify key variables.\n",
    "# Could be useful to decide which variables to retain.\n",
    "\n",
    "cfs(form, ds[vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Any variables to remove because not useful?\n",
    "\n",
    "vars %<>% setdiff(NULL) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "Or, we can use the function information.gain() to identify varaible importance and decide which varaibles to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Use information gain to identify variable importance.\n",
    "\n",
    "information.gain(form, ds[vars]) %>%\n",
    "  rownames_to_column() %>%\n",
    "  arrange(attr_importance)\n",
    "\n",
    "# Any variables to remove because not useful?\n",
    "\n",
    "vars %<>% setdiff(NULL)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.6: Clean - Remove Missing Target\n",
    "\n",
    "In addition to varaibles, sometimes there may be further cleansing with the observations. Here, we remove observations with a missing target first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Continue Wrangling\n",
    "\n",
    "# Check the dimensions to start with.\n",
    "\n",
    "dim(ds) %>% echo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify observations with a missing target.\n",
    "\n",
    "ds %>% \n",
    "  extract2(target) %>% \n",
    "  is.na() %T>%\n",
    "  {sum(.) %>% print()} ->\n",
    "missing.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Remove observations with a missing target.\n",
    "\n",
    "ds %<>% filter(!missing.target)\n",
    "\n",
    "# Confirm the filter delivered the expected dataset.\n",
    "\n",
    "dim(ds) %>% echo()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.7: Clean - Deal with Missing Values\n",
    "\n",
    "To clean observatons with missing predictors, we can impute missing values in the data by using na.roughfix() from package randomForest (Breiman et al, 2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "## Optional missing value imputation.\n",
    "\n",
    "# Count the number of missing values.\n",
    "\n",
    "ds[vars] %>%  is.na() %>% sum() %>% echo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Impute missing values.\n",
    "\n",
    "ds[vars] %<>% na.roughfix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm that no missing values remain.\n",
    "\n",
    "ds[vars] %>%  is.na() %>% sum() %>% echo()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "Alternatively, we can simply remove observations that have missing values. Here na.omit() identifies the rows to omit based on the vars to be included for modelling. This list of rows to omit is stored as the na.action attribute of the returned object. We then remove these observations from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Optional remove observations with missing values.\n",
    "\n",
    "# Initialise the list of observations to be removed.\n",
    "\n",
    "omit <- NULL\n",
    "\n",
    "# Review the current dataset.\n",
    "\n",
    "ds[vars] %>% nrow() %>% echo()\n",
    "ds[vars] %>% is.na() %>% sum() %>% echo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify any observations with missing values.\n",
    "\n",
    "ds[vars] %>%\n",
    "  na.omit() %>%\n",
    "  attr(\"na.action\") %T>%\n",
    "  print() ->\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Record the observations to omit.\n",
    "\n",
    "omit <- union(omit, mo) %T>% {length(.) %>% print()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# If there are observations to omit then remove them.\n",
    "\n",
    "if (length(omit)) ds <- ds[-omit,]\n",
    "\n",
    "# Confirm the observations have been removed.\n",
    "\n",
    "ds[vars] %>% nrow() %>% echo()\n",
    "ds[vars] %>% is.na() %>% sum() %>% echo()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.8: Clean - Normalise Factors\n",
    "\n",
    "Some variables will have levels with spaces, and mixture of cases, etc. We may like to normalise the levels for each of the categoric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Normalise factors.\n",
    "\n",
    "# Note which variables are categoric.\n",
    "\n",
    "ds[vars] %>%\n",
    "  sapply(is.factor) %>%\n",
    "  which() %>%\n",
    "  names() %T>%\n",
    "  print() ->\n",
    "catc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Check the levels.\n",
    "\n",
    "ds[catc] %>% sapply(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Normalise the levels of all categoric variables.\n",
    "\n",
    "for (v in catc) \n",
    "  levels(ds[[v]]) %<>% normVarNames()\n",
    "\n",
    "# Review the levels.\n",
    "\n",
    "ds[catc] %>% sapply(levels)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 3.9: Clean - Ensure Target is Numeric\n",
    "\n",
    "For classification models, we want to ensure the target is factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure the target is factor.\n",
    "\n",
    "class(ds[[target]])\n",
    "\n",
    "ds[[target]] %<>% as.factor()\n",
    "\n",
    "# Confirm the distribution.\n",
    "\n",
    "ds[target] %>% summary()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "Here, we visualise the distribution of the target variable using ggplot2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "p <- ggplot(ds, aes_string(x=target))\n",
    "p <- p + geom_bar(width=0.2)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 4.1: Prepare - Variable\n",
    "\n",
    "We are now ready to identify the variables that we will use to build the model. Previously we identified the variable roles. Now we identify those that we wish to model. We begin with the model input variables, identifying them as a vector of characters (the variable name) and a vector of integers (the variable index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# VARIABLE ROLES\n",
    "\n",
    "# Identify the input variables by name.\n",
    "\n",
    "inputs <- setdiff(vars, target) %T>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the input variables by index.\n",
    "\n",
    "inputi <- sapply(inputs, \n",
    "                 function(x) which(x == names(ds)), \n",
    "                 USE.NAMES=FALSE) %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "For convenience we record the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "nobs <- nrow(ds) %T>% echo()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "Here we simply report on the dimensions of various data subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm various subset sizes.\n",
    "\n",
    "dim(ds) %>% echo()\n",
    "dim(ds[vars]) %>% echo()\n",
    "dim(ds[inputs]) %>% echo()\n",
    "dim(ds[inputi]) %>% echo()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 4.2: Prepare - Numeric and Categoric Variables\n",
    "\n",
    "Sometimes we need to identify the numeric and categoric variables. Many cluster analysis algorithms only deal with numeric variables, for example. Here we identify them both by name and by index. Note that when using the index we have to assume the variables always remain in the same order within the dataset and all variables are present. Otherwise the indicies will get out of sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the numeric variables by index.\n",
    "\n",
    "ds %>%\n",
    "  sapply(is.numeric) %>%\n",
    "  which() %>%\n",
    "  intersect(inputi) %T>%\n",
    "  print() ->\n",
    "numi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the numeric variables by name.\n",
    "\n",
    "numc <- \n",
    "  ds %>% \n",
    "  names() %>% \n",
    "  '['(numi) %T>% \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the categoric variables by index.\n",
    "\n",
    "ds %>%\n",
    "  sapply(is.factor) %>%\n",
    "  which() %>%\n",
    "  intersect(inputi) %T>%\n",
    "  print() ->\n",
    "cati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the categoric variables by name.\n",
    "\n",
    "ds %>% \n",
    "  names() %>% \n",
    "  '['(cati) %T>% \n",
    "  print() ->\n",
    "catc"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
   "source": [
    "# Step 4.3: Prepare - Save Dataset\n",
    "\n",
    "For large datasets we may want to save it to a bianry .RData file once we have it in the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# SAVE THE DATASET\n",
    "\n",
    "# We will use a fixed timestamp to identify our file for convenience.\n",
    "\n",
    "dsdate <- \"_20161215\"\n",
    "\n",
    "# Filename for the saved dataset.\n",
    "\n",
    "dsrdata <- \n",
    "  file.path(fpath, dsname %s+% dsdate %s+% \".RData\") %T>% \n",
    "  print()\n",
    "\n",
    "# Save relevant R objects to the binary RData file.\n",
    "\n",
    "save(ds, dsname, dspath, dsdate, nobs,\n",
    "     vars, target, id, ignore, omit, \n",
    "     inputi, inputs, numi, numc, cati, catc, \n",
    "     file=dsrdata)"
   ]
  }
 ],
  "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
