{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Science Design Pattern for Student Drop Out\"\n",
    "author: \"Microsoft\"\n",
    "output: \n",
    "    rmarkdown::html_vignette:\n",
    "        toc: true\n",
    "\n",
    "vignette: >\n",
    "  %\\VignetteIndexEntry{Vignette Title}\n",
    "  %\\VignetteEngine{knitr::rmarkdown}\n",
    "  %\\VignetteEncoding{UTF-8}\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "knitr::opts_chunk$set(fig.width = 6,\n",
    "                      fig.height = 4,\n",
    "                      fig.align='center',\n",
    "                      dev = \"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducation\n",
    "\n",
    "Welcome to the Data Science Design Pattern for Student Drop Out. This pattern provides a starting point for the data scientist exploring a new dataset. By no means is it the end point of the data science journey. The pattern is under regular revision and improvement and is provided as is. \n",
    "\n",
    "We now introduce a generic pattern for building multiple binary classification models using R.\n",
    "\n",
    "# Pre-configuration\n",
    "\n",
    "We load the R packages required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rattle: A free graphical interface for data mining with R.\n",
      "Version 4.1.0 Copyright (c) 2006-2015 Togaware Pty Ltd.\n",
      "Type 'rattle()' to shake, rattle, and roll your data.\n",
      "Loading required package: BBmisc\n",
      "Loading required package: ggplot2\n",
      "Loading required package: ParamHelpers\n",
      "Loading required package: foreach\n",
      "Loading required package: doParallel\n",
      "Loading required package: iterators\n",
      "Loading required package: parallel\n",
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "Loading required package: grid\n",
      "\n",
      "Attaching package: 'grid'\n",
      "\n",
      "The following object is masked from 'package:BBmisc':\n",
      "\n",
      "    explode\n",
      "\n",
      "Loading required package: mvtnorm\n",
      "Loading required package: modeltools\n",
      "Loading required package: stats4\n",
      "Loading required package: strucchange\n",
      "Loading required package: zoo\n",
      "\n",
      "Attaching package: 'zoo'\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Loading required package: sandwich\n",
      "\n",
      "Attaching package: 'e1071'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    impute\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    train\n",
      "\n",
      "Loading required package: gplots\n",
      "\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "\n",
      "Attaching package: 'ROCR'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    performance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# R SETUP\n",
    "\n",
    "# Load required packages from local library into R.\n",
    "\n",
    "library(magrittr)     # Data pipelines: %>% %T>% %<>%.\n",
    "library(stringi)      # String operator: %s+%.\n",
    "library(rattle)       # Evaluate using riskchart().\n",
    "library(mlr)          # Dependency of unbalanced.\n",
    "library(unbalanced)   # Resampling using ubSMOTE.\n",
    "library(rpart)        # Model: decision tree.\n",
    "library(rpart.plot)   # Draw fancyRpartPlot().\n",
    "library(randomForest) # Model: random forest.\n",
    "library(ada)          # Model: ada boosting.\n",
    "library(party)        # Model: ctree and cforest.\n",
    "library(e1071)        # Model: support vector machine.\n",
    "library(nnet)         # Model: neural network.\n",
    "library(Matrix)       # Construct a Matrix of a class that inherits from Matrix.\n",
    "library(caret)        # Tune model hyper-parameters.\n",
    "library(xgboost)      # Model: extreme gradiant boosting.\n",
    "library(Ckmeans.1d.dp)# Plot feature importance using xgb.plot.importance.\n",
    "library(DiagrammeR)   # Plot xgboost tree using xgb.plot.tree.\n",
    "library(ROCR)         # Use prediction() for evaluation.\n",
    "library(pROC)         # Use auc() for evaluation. \n",
    "library(ggplot2)      # Visually evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.4: Re-load Dataset\n",
    "\n",
    "In the Data template we loaded the studentDropIndia dataset, processed it, and saved it to file. Here we re-load the dataset and review its contents. In addition, we define some support functions for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"data/studentDropIndia_20161215.RData\"\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# DATA INGESTION\n",
    "\n",
    "# Identify the dataset.\n",
    "\n",
    "dsname <- \"studentDropIndia\"\n",
    "\n",
    "# We define some support functions that we often find useful.\n",
    "\n",
    "evaluateModel <- function(data, observed, predicted) \n",
    "{ \n",
    "  # Calculate the confusion matrix\n",
    "  \n",
    "  confusion <- table(data[[observed]], data[[predicted]], dnn=c(\"Observed\", \"Predicted\"))\n",
    "  confusion %>% print()\n",
    "  \n",
    "  # Calculate the performance metrics\n",
    "  \n",
    "  tp <- confusion[rownames(confusion) == 1, colnames(confusion) == 1]\n",
    "  fn <- confusion[rownames(confusion) == 1, colnames(confusion) == 0]\n",
    "  fp <- confusion[rownames(confusion) == 0, colnames(confusion) == 1]\n",
    "  tn <- confusion[rownames(confusion) == 0, colnames(confusion) == 0]\n",
    "  \n",
    "  accuracy <- (tp + tn) / (tp + fn + fp + tn)\n",
    "  precision <- tp / (tp + fp)\n",
    "  recall <- tp / (tp + fn)\n",
    "  fscore <- 2 * (precision * recall) / (precision + recall)\n",
    "  \n",
    "  # Construct the vector of performance metrics\n",
    "  \n",
    "  metrics <- c(\"Accuracy\" = accuracy,\n",
    "               \"Precision\" = precision,\n",
    "               \"Recall\" = recall,\n",
    "               \"F-Score\" = fscore)\n",
    "  \n",
    "  # Return the vector of performance metrics\n",
    "  \n",
    "  return(metrics)\n",
    "}\n",
    "\n",
    "rocChart <- function(pr, target)\n",
    "{\n",
    "  # Calculate the true positive and the false positive rates.\n",
    "  \n",
    "  rates <- pr %>%\n",
    "    prediction(target) %>%\n",
    "    performance(\"tpr\", \"fpr\")\n",
    "  \n",
    "  # Calulcate the AUC.\n",
    "  \n",
    "  auc <- pr %>%\n",
    "    prediction(target) %>%\n",
    "    performance(\"auc\") %>%\n",
    "    attr(\"y.values\") %>%\n",
    "    extract2(1)\n",
    "  \n",
    "  # Construct the plot.\n",
    "  \n",
    "  pl <- data.frame(tpr=attr(rates, \"y.values\")[[1]], \n",
    "                   fpr=attr(rates, \"x.values\")[[1]]) %>%\n",
    "    ggplot(aes(fpr, tpr)) +\n",
    "    geom_line() +\n",
    "    annotate(\"text\", x=0.875, y=0.125, vjust=0,\n",
    "             label=paste(\"AUC =\", round(100*auc, 2)), \n",
    "             family=\"xkcd\") +\n",
    "    xlab(\"False Positive Rate (1-Specificity)\") +\n",
    "    ylab(\"True Positive Rate (Sensitivity)\")\n",
    "  \n",
    "  # Return the plot object.\n",
    "  \n",
    "  return(pl)\n",
    "}\n",
    "\n",
    "# Identify the dataset to load.\n",
    "\n",
    "fpath  <- \"data\"\n",
    "dsdate <- \"_\" %s+% \"20161215\"\n",
    "\n",
    "# Filename of the saved dataset.\n",
    "\n",
    "dsrdata <-\n",
    "  file.path(fpath, dsname %s+% dsdate %s+% \".RData\") %T>% \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"ds\"     \"dsname\" \"dspath\" \"dsdate\" \"nobs\"   \"vars\"   \"target\" \"id\"    \n",
      " [9] \"ignore\" \"omit\"   \"inputi\" \"inputs\" \"numi\"   \"numc\"   \"cati\"   \"catc\"  \n"
     ]
    }
   ],
   "source": [
    "# Load the R objects from file and list them.\n",
    "\n",
    "load(dsrdata) %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'studentDropIndia'"
      ],
      "text/latex": [
       "'studentDropIndia'"
      ],
      "text/markdown": [
       "'studentDropIndia'"
      ],
      "text/plain": [
       "[1] \"studentDropIndia\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'C:/Users/zhouf/Documents/Revolution Analytics/Projects/Education2/Demo/studentDropIndia_20161215.csv'"
      ],
      "text/latex": [
       "'C:/Users/zhouf/Documents/Revolution Analytics/Projects/Education2/Demo/studentDropIndia\\_20161215.csv'"
      ],
      "text/markdown": [
       "'C:/Users/zhouf/Documents/Revolution Analytics/Projects/Education2/Demo/studentDropIndia_20161215.csv'"
      ],
      "text/plain": [
       "[1] \"C:/Users/zhouf/Documents/Revolution Analytics/Projects/Education2/Demo/studentDropIndia_20161215.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'_20161215'"
      ],
      "text/latex": [
       "'\\_20161215'"
      ],
      "text/markdown": [
       "'_20161215'"
      ],
      "text/plain": [
       "[1] \"_20161215\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "19100"
      ],
      "text/latex": [
       "19100"
      ],
      "text/markdown": [
       "19100"
      ],
      "text/plain": [
       "[1] 19100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'continue_drop'</li>\n",
       "\t<li>'gender'</li>\n",
       "\t<li>'caste'</li>\n",
       "\t<li>'mathematics_marks'</li>\n",
       "\t<li>'english_marks'</li>\n",
       "\t<li>'science_marks'</li>\n",
       "\t<li>'science_teacher'</li>\n",
       "\t<li>'languages_teacher'</li>\n",
       "\t<li>'guardian'</li>\n",
       "\t<li>'internet'</li>\n",
       "\t<li>'total_students'</li>\n",
       "\t<li>'total_toilets'</li>\n",
       "\t<li>'establishment_year'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'continue\\_drop'\n",
       "\\item 'gender'\n",
       "\\item 'caste'\n",
       "\\item 'mathematics\\_marks'\n",
       "\\item 'english\\_marks'\n",
       "\\item 'science\\_marks'\n",
       "\\item 'science\\_teacher'\n",
       "\\item 'languages\\_teacher'\n",
       "\\item 'guardian'\n",
       "\\item 'internet'\n",
       "\\item 'total\\_students'\n",
       "\\item 'total\\_toilets'\n",
       "\\item 'establishment\\_year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'continue_drop'\n",
       "2. 'gender'\n",
       "3. 'caste'\n",
       "4. 'mathematics_marks'\n",
       "5. 'english_marks'\n",
       "6. 'science_marks'\n",
       "7. 'science_teacher'\n",
       "8. 'languages_teacher'\n",
       "9. 'guardian'\n",
       "10. 'internet'\n",
       "11. 'total_students'\n",
       "12. 'total_toilets'\n",
       "13. 'establishment_year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"continue_drop\"      \"gender\"             \"caste\"             \n",
       " [4] \"mathematics_marks\"  \"english_marks\"      \"science_marks\"     \n",
       " [7] \"science_teacher\"    \"languages_teacher\"  \"guardian\"          \n",
       "[10] \"internet\"           \"total_students\"     \"total_toilets\"     \n",
       "[13] \"establishment_year\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'continue_drop'"
      ],
      "text/latex": [
       "'continue\\_drop'"
      ],
      "text/markdown": [
       "'continue_drop'"
      ],
      "text/plain": [
       "[1] \"continue_drop\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'student_id'</li>\n",
       "\t<li>'school_id'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'student\\_id'\n",
       "\\item 'school\\_id'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'student_id'\n",
       "2. 'school_id'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"student_id\" \"school_id\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'student_id'</li>\n",
       "\t<li>'school_id'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'student\\_id'\n",
       "\\item 'school\\_id'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'student_id'\n",
       "2. 'school_id'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"student_id\" \"school_id\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the metadata.\n",
    "\n",
    "dsname\n",
    "dspath\n",
    "dsdate\n",
    "nobs\n",
    "vars\n",
    "target\n",
    "id\n",
    "ignore\n",
    "omit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.5: Prepare - Formula to Describe the Goal\n",
    "\n",
    "We continue on from the Data module where we had Steps 1, 2, and 3 and the beginnings of Step 4 of a data mining process.\n",
    "\n",
    "The next step is to describe the model to be built by way of writing a formula to capture our intent. The formula describes the model to be built as being constructed to predict the target variable based on the other (suitable) variables available in the dataset. The notation used to express this is to name the target (continue_drop), followed by a tilde (~) followed by a period (.) to represent all other variables (these variables will be listed in vars in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue_drop ~ gender + caste + mathematics_marks + english_marks + \n",
      "    science_marks + science_teacher + languages_teacher + guardian + \n",
      "    internet + total_students + total_toilets + establishment_year\n",
      "<environment: 0x000000001e5e2c90>\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# PREPARE FOR MODELLING\n",
    "\n",
    "# Formula for modelling.\n",
    "\n",
    "form <- ds[vars] %>% formula() %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common methodology for model building is to randomly partition the available data into a training dataset and testing dataset. We sometimes also introducing a third dataset called the validation dataset, used during the building of the model, but for now we will use just the two.\n",
    "\n",
    "First we (optionally) initiate the random number sequence with a randomly selected seed, and report what the seed is so that we could repeat the experiments presented here if required. For consistency in this module we use a particular seed of 123.\n",
    "\n",
    "Next we partition the dataset into two subsets. The first is a 70% random sample for building the model (the training dataset) and the second is the remainder, used to evaluate the performance of the model (the testing dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 13370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5493</li>\n",
       "\t<li>15056</li>\n",
       "\t<li>7811</li>\n",
       "\t<li>16863</li>\n",
       "\t<li>17960</li>\n",
       "\t<li>870</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5493\n",
       "\\item 15056\n",
       "\\item 7811\n",
       "\\item 16863\n",
       "\\item 17960\n",
       "\\item 870\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5493\n",
       "2. 15056\n",
       "3. 7811\n",
       "4. 16863\n",
       "5. 17960\n",
       "6. 870\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  5493 15056  7811 16863 17960   870"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 5730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>6</li>\n",
       "\t<li>15</li>\n",
       "\t<li>16</li>\n",
       "\t<li>17</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 6\n",
       "\\item 15\n",
       "\\item 16\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 3\n",
       "3. 6\n",
       "4. 15\n",
       "5. 16\n",
       "6. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  2  3  6 15 16 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise random numbers for repeatable results.\n",
    "\n",
    "seed <- 123\n",
    "set.seed(seed)\n",
    "\n",
    "# Partition the full dataset into two.\n",
    "\n",
    "train <- \n",
    "  sample(nobs, 0.70*nobs) %T>% \n",
    "  {length(.) %>% print()}\n",
    "\n",
    "head(train)\n",
    "\n",
    "test <- \n",
    "  seq_len(nobs) %>%\n",
    "  setdiff(train) %T>%\n",
    "  {length(.) %>% print()}\n",
    "\n",
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Resampling - Rebalancing the Proportion of Minority over Majority (Optional)\n",
    "\n",
    "Since the proportion of minority class (student dropping-out) is around 5% among the whole dataset, we here implement the SMOTE on the training dataset by using the function ubSMOTE from the R package “unbalanced”. This yields a dropping-out proportion of 23% among all the training data. By using the training dataset after SMOTE as the modeling input, we can greatly improve the model performance, especially when applying some of the algorithms not suitable for unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        0         1 \n",
       "0.7692308 0.2307692 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebalance the training dataset.\n",
    "\n",
    "traindata <- as.data.frame(ds[train, inputs])\n",
    "traintarget <- as.factor(as.numeric(as.data.frame(ds[train, target])[[1]])-1)\n",
    "\n",
    "smote <- ubSMOTE(X=traindata, Y=traintarget,\n",
    "                 perc.over=200, perc.under=500,\n",
    "                 k=3, verbose=TRUE) \n",
    "\n",
    "trainsmote <- cbind(smote$X, smote$Y)\n",
    "names(trainsmote)[names(trainsmote) == \"smote$Y\"] <- \"continue_drop\"\n",
    "\n",
    "traindata <- trainsmote\n",
    "\n",
    "# Check the dropping-out proportion\n",
    "\n",
    "table(traindata$continue_drop)/nrow(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.1: Build - Decision Tree Model\n",
    "\n",
    "The commonly used classification model builders include rpart() decision tree, randomForest() random forest, ada() stochastic boosting, ect. Now we build an rpart() decision tree, as a baseline model builder. Note that our models from now on are all built on the original training dataset in the purpose of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   0.17    0.00    0.18 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "n= 13370 \n",
       "\n",
       "node), split, n, loss, yval, (yprob)\n",
       "      * denotes terminal node\n",
       "\n",
       " 1) root 13370 645 continue (0.95175767 0.04824233)  \n",
       "   2) english_marks< 0.9975 13334 609 continue (0.95432728 0.04567272)  \n",
       "     4) science_teacher< 5.5 9625 244 continue (0.97464935 0.02535065) *\n",
       "     5) science_teacher>=5.5 3709 365 continue (0.90159073 0.09840927)  \n",
       "      10) english_marks>=0.228 3671 327 continue (0.91092345 0.08907655) *\n",
       "      11) english_marks< 0.228 38   0 drop (0.00000000 1.00000000) *\n",
       "   3) english_marks>=0.9975 36   0 drop (0.00000000 1.00000000) *"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: rpart\n",
    "\n",
    "ctrl <- rpart.control(maxdepth=3)\n",
    "system.time(m.rp <- rpart(form, ds[train, vars], control=ctrl))\n",
    "m.rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Record the type of the model for later use.\n",
    "\n",
    "mtype <- \"rpart\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAmVBMVEUAAAAgNEEjOyMrR1cv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\nAEQCMAAiARgAkQAM8P+6IVpUqe4GHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fancyRpartPlot(m.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.2: Evaluate - Decision Tree Model\n",
    "\n",
    "As we have noted though, performing any evaluation on the training dataset provides a biased estimate of the actual performance. We must instead evaluate the performance of our models on a previously unseen dataset (at least unseen by the algorithm building the model).\n",
    "\n",
    "So we now evaluate the model performance on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>continue_drop</th><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>rpart_prediction</th><th scope=col>rpart_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>continue  </td><td>f         </td><td>bc        </td><td>0.290     </td><td>0.512     </td><td>0.290     </td><td>4         </td><td> 7        </td><td>mother    </td><td>true      </td><td>356       </td><td>14        </td><td>1943      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>continue  </td><td>f         </td><td>oc        </td><td>0.602     </td><td>0.666     </td><td>0.602     </td><td>4         </td><td> 2        </td><td>mother    </td><td>false     </td><td>179       </td><td> 8        </td><td>1955      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>continue  </td><td>f         </td><td>bc        </td><td>0.594     </td><td>0.519     </td><td>0.594     </td><td>4         </td><td> 8        </td><td>mother    </td><td>true      </td><td>335       </td><td>43        </td><td>1916      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>continue  </td><td>f         </td><td>bc        </td><td>0.461     </td><td>0.524     </td><td>0.461     </td><td>0         </td><td> 3        </td><td>mother    </td><td>true      </td><td>469       </td><td>14        </td><td>1905      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>continue  </td><td>f         </td><td>oc        </td><td>0.742     </td><td>0.672     </td><td>0.742     </td><td>3         </td><td>12        </td><td>mother    </td><td>true      </td><td>132       </td><td>14        </td><td>1996      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>drop      </td><td>f         </td><td>bc        </td><td>0.503     </td><td>0.523     </td><td>0.503     </td><td>9         </td><td> 0        </td><td>father    </td><td>true      </td><td>397       </td><td> 5        </td><td>1950      </td><td>0         </td><td>0.08907655</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & continue\\_drop & gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & rpart\\_prediction & rpart\\_probability\\\\\n",
       "\\hline\n",
       "\t2 & continue   & f          & bc         & 0.290      & 0.512      & 0.290      & 4          &  7         & mother     & true       & 356        & 14         & 1943       & 0          & 0.02535065\\\\\n",
       "\t3 & continue   & f          & oc         & 0.602      & 0.666      & 0.602      & 4          &  2         & mother     & false      & 179        &  8         & 1955       & 0          & 0.02535065\\\\\n",
       "\t6 & continue   & f          & bc         & 0.594      & 0.519      & 0.594      & 4          &  8         & mother     & true       & 335        & 43         & 1916       & 0          & 0.02535065\\\\\n",
       "\t15 & continue   & f          & bc         & 0.461      & 0.524      & 0.461      & 0          &  3         & mother     & true       & 469        & 14         & 1905       & 0          & 0.02535065\\\\\n",
       "\t16 & continue   & f          & oc         & 0.742      & 0.672      & 0.742      & 3          & 12         & mother     & true       & 132        & 14         & 1996       & 0          & 0.02535065\\\\\n",
       "\t17 & drop       & f          & bc         & 0.503      & 0.523      & 0.503      & 9          &  0         & father     & true       & 397        &  5         & 1950       & 0          & 0.08907655\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   continue_drop gender caste mathematics_marks english_marks science_marks\n",
       "2  continue      f      bc    0.290             0.512         0.290        \n",
       "3  continue      f      oc    0.602             0.666         0.602        \n",
       "6  continue      f      bc    0.594             0.519         0.594        \n",
       "15 continue      f      bc    0.461             0.524         0.461        \n",
       "16 continue      f      oc    0.742             0.672         0.742        \n",
       "17 drop          f      bc    0.503             0.523         0.503        \n",
       "   science_teacher languages_teacher guardian internet total_students\n",
       "2  4                7                mother   true     356           \n",
       "3  4                2                mother   false    179           \n",
       "6  4                8                mother   true     335           \n",
       "15 0                3                mother   true     469           \n",
       "16 3               12                mother   true     132           \n",
       "17 9                0                father   true     397           \n",
       "   total_toilets establishment_year rpart_prediction rpart_probability\n",
       "2  14            1943               0                0.02535065       \n",
       "3   8            1955               0                0.02535065       \n",
       "6  43            1916               0                0.02535065       \n",
       "15 14            1905               0                0.02535065       \n",
       "16 14            1996               0                0.02535065       \n",
       "17  5            1950               0                0.08907655       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.rp, ds[test, vars], type=\"prob\")\n",
    "threshold <- 0.5\n",
    "rpart_probability <- predictions[, 2]\n",
    "rpart_prediction <- ifelse(rpart_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], rpart_prediction, rpart_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5475    0\n",
      "       1  229   26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.960034904013962</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>0.101960784313725</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>0.185053380782918</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.960034904013962\n",
       "\\item[Precision] 1\n",
       "\\item[Recall] 0.101960784313725\n",
       "\\item[F-Score] 0.185053380782918\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.960034904013962Precision\n",
       ":   1Recall\n",
       ":   0.101960784313725F-Score\n",
       ":   0.185053380782918\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "0.9600349 1.0000000 0.1019608 0.1850534 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nJEVxiERSFIdIJEVxiERSFIdIJEVxyP8Dv9SADqN240UAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.rp <- evaluateModel(data=pred,\n",
    "                            observed=\"continue_drop\",\n",
    "                            predicted=\"rpart_prediction\")\n",
    "metrics.rp\n",
    "\n",
    "rocChart(pr=pred$rpart_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.3: Compare - Multiple Models using Experiment\n",
    "\n",
    "We can repeat the modelling multiple times, randomly selecting different datasets for training, to get an estimate of the actual expected performance and variation we see in the performance. The helper function experi() can be used to assist us here. It is available as http://onepager.togaware.com/experi.R and we show some of the coding of experi() below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the function experi()\n",
    "\n",
    "experi <- function(form, ds, dsname, target, modeller, details=\"\",\n",
    "                   n=100, control=NULL,\n",
    "                   keep=FALSE, # Keep the last model built.\n",
    "                   prob=\"prob\",   \n",
    "                   class=\"class\",\n",
    "                   log=\"experi.log\")\n",
    "{\n",
    " suppressPackageStartupMessages(require(pROC))\n",
    "  \n",
    " user <- Sys.getenv(\"LOGNAME\")\n",
    " node <- Sys.info()[[\"nodename\"]]\n",
    " \n",
    " wsrpart.model <- modeller==\"wsrpart\"\n",
    " \n",
    " numclass <- length(levels(ds[,target]))\n",
    " \n",
    " start.time <- proc.time()\n",
    " \n",
    " seeds <- cors <- strs <- aucs <- accs <- NULL\n",
    " for (i in seq_len(n))\n",
    "{\n",
    " loop.time <- proc.time()\n",
    " \n",
    " seeds <- c(seeds, seed <- sample(1:1000000, 1))\n",
    " set.seed(seed)\n",
    " \n",
    "....\n",
    "\n",
    " result[-c(1:7)] <- round(result[-c(1:7)], 2)\n",
    " row.names(result) <- NULL\n",
    " if (keep)\n",
    " {\n",
    "  if (numclass==2)\n",
    "  {\n",
    "   attr(result, \"pr\") <- pr\n",
    "   attr(result, \"test\") <- test\n",
    "  }\n",
    "  attr(result, \"model\") <- model\n",
    " }\n",
    "}\n",
    "return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the experiments using the algorihtms rpart (Therneau and Atkinson, 2014), randomForest (Breiman et al., 2012), ada (Culp et al., 2012), ctree() from party (Hothorn et al., 2013). In such way, we can conveniently implement those models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lubridate\n",
      "\n",
      "Attaching package: 'lubridate'\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    date\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>auc</th><th scope=col>auc.sd</th><th scope=col>cor</th><th scope=col>cor.sd</th><th scope=col>str</th><th scope=col>str.sd</th><th scope=col>acc</th><th scope=col>acc.sd</th><th scope=col>n</th><th scope=col>user</th><th scope=col>elapsed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>rpart_1</th><td>0.99  </td><td>0.02  </td><td>NA    </td><td>NA    </td><td>NA    </td><td>NA    </td><td>1     </td><td>0     </td><td>10    </td><td>  4.09</td><td>  4.32</td></tr>\n",
       "\t<tr><th scope=row>randomForest_500</th><td>1.00  </td><td>0.00  </td><td>NA    </td><td>NA    </td><td>NA    </td><td>NA    </td><td>1     </td><td>0     </td><td>10    </td><td> 66.67</td><td> 70.73</td></tr>\n",
       "\t<tr><th scope=row>ada_50</th><td>1.00  </td><td>0.00  </td><td>NA    </td><td>NA    </td><td>NA    </td><td>NA    </td><td>1     </td><td>0     </td><td>10    </td><td>155.28</td><td>156.28</td></tr>\n",
       "\t<tr><th scope=row>ctree_1</th><td>1.00  </td><td>0.00  </td><td>NA    </td><td>NA    </td><td>NA    </td><td>NA    </td><td>1     </td><td>0     </td><td>10    </td><td>  5.56</td><td>  5.68</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & auc & auc.sd & cor & cor.sd & str & str.sd & acc & acc.sd & n & user & elapsed\\\\\n",
       "\\hline\n",
       "\trpart\\_1 & 0.99   & 0.02   & NA     & NA     & NA     & NA     & 1      & 0      & 10     &   4.09 &   4.32\\\\\n",
       "\trandomForest\\_500 & 1.00   & 0.00   & NA     & NA     & NA     & NA     & 1      & 0      & 10     &  66.67 &  70.73\\\\\n",
       "\tada\\_50 & 1.00   & 0.00   & NA     & NA     & NA     & NA     & 1      & 0      & 10     & 155.28 & 156.28\\\\\n",
       "\tctree\\_1 & 1.00   & 0.00   & NA     & NA     & NA     & NA     & 1      & 0      & 10     &   5.56 &   5.68\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "                 auc  auc.sd cor cor.sd str str.sd acc acc.sd n  user   elapsed\n",
       "rpart_1          0.99 0.02   NA  NA     NA  NA     1   0      10   4.09   4.32 \n",
       "randomForest_500 1.00 0.00   NA  NA     NA  NA     1   0      10  66.67  70.73 \n",
       "ada_50           1.00 0.00   NA  NA     NA  NA     1   0      10 155.28 156.28 \n",
       "ctree_1          1.00 0.00   NA  NA     NA  NA     1   0      10   5.56   5.68 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source experi.R \n",
    "\n",
    "source(\"http://onepager.togaware.com/experi.R\")\n",
    "\n",
    "# Set the times of loops\n",
    "\n",
    "n <- 10\n",
    "\n",
    "# Run experiments\n",
    "\n",
    "ex.rp <- experi(form, ds[vars], dsname, target, \"rpart\", \"1\", n=n, keep=TRUE)\n",
    "ex.rf <- experi(form, ds[vars], dsname, target, \"randomForest\", \"500\", n=n, keep=TRUE, control=list(na.action=na.omit))\n",
    "ex.ad <- experi(form, ds[vars], dsname, target, \"ada\", \"50\", n=n, keep=TRUE)\n",
    "ex.ct <- experi(form, ds[vars], dsname, target, \"ctree\", \"1\", n=n, keep=TRUE)\n",
    "\n",
    "# Compare results\n",
    "\n",
    "results <- rbind(ex.rp, ex.rf, ex.ad, ex.ct)\n",
    "rownames(results) <- results$modeller\n",
    "results$modeller <- NULL\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.1: Other Models - Support Vector Machine Model\n",
    "\n",
    "Except for the above commonly used binary classification models, we could also try some more advanced models, for instance, svm(), support vector machine, nnet(), neural network, xgboost(), extreme gradient boosting, ect. We firstly build a svm() support vector machine model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    "system.time({\n",
    "m.svm.cv <- tune.svm(form, \n",
    "                     data=ds[train, vars], \n",
    "                     gamma=2^(-1:1), \n",
    "                     cost=2^(2:4), \n",
    "                     type=\"C-classification\",\n",
    "                     probability=TRUE,\n",
    "                     scale=FALSE)\n",
    "})\n",
    "\n",
    "print(m.svm.cv$best.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model: svm\n",
    "\n",
    "system.time({\n",
    "  m.svm <- svm(form, \n",
    "               data=ds[train, vars], \n",
    "               gamma=m.svm.cv$best.parameters[1], \n",
    "               cost=m.svm.cv$best.parameters[2],\n",
    "               type=\"C-classification\",\n",
    "               probability = TRUE,\n",
    "               scale = FALSE)\n",
    "})\n",
    "\n",
    "# Check the model information\n",
    "\n",
    "m.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score model \n",
    "\n",
    "predictions <- predict(m.svm, ds[test, vars], probability=TRUE)\n",
    "threshold <- 0.5\n",
    "svm_probability <- attr(predictions, 'probabilities')[, 2]\n",
    "svm_prediction <- ifelse(svm_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], svm_prediction, svm_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.svm <- evaluateModel(data=pred,\n",
    "                              observed=\"continue_drop\",\n",
    "                              predicted=\"svm_prediction\")\n",
    "metrics.svm\n",
    "\n",
    "rocChart(pr=pred$svm_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.2: Other Models - Neural Network Model\n",
    "\n",
    "Next we build a nnet(), neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    "system.time({\n",
    "m.nnet.cv <- tune.nnet(form, \n",
    "                       data=ds[train, vars], \n",
    "                       size=c(6, 8, 10), \n",
    "                       decay=5*10^(-3:-1), \n",
    "                       rang=0.1,\n",
    "                       maxit=200)\n",
    "})\n",
    "\n",
    "print(m.nnet.cv$best.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model: nnet\n",
    "\n",
    "system.time({\n",
    "  m.nnet <- nnet(formula=form,\n",
    "                 data=ds[train, vars],\n",
    "                 size=m.nnet.cv$best.parameters[1], \n",
    "                 decay=m.nnet.cv$best.parameters[2], \n",
    "                 rang=0.1,\n",
    "                 maxit=200)\n",
    "})\n",
    "\n",
    "# Check the model information\n",
    "\n",
    "m.nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.nnet, ds[test, vars], type=\"raw\")\n",
    "threshold <- 0.5\n",
    "nnet_probability <- predictions\n",
    "nnet_prediction <- ifelse(nnet_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], nnet_prediction, nnet_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.nnet <- evaluateModel(data=pred,\n",
    "                              observed=\"continue_drop\",\n",
    "                              predicted=\"nnet_prediction\")\n",
    "metrics.nnet\n",
    "\n",
    "rocChart(pr=pred$nnet_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.3: Other Models - Extreme Gradient Boosting Model\n",
    "\n",
    "Finally, we build a xgboost() extreme gradient boosting, as a specicial example, which performs well when dealing with unbalanced data. In our case, the proportion of student drop-out is around 5% in the original training dataset. Here we just use it as input to demonstrate the power of xgboost() in dealing with unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ data :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  .. ..@ i       : int [1:158037] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  .. ..@ p       : int [1:13] 0 13370 26740 40110 53480 66850 79090 91187 104557 117927 ...\n",
      "  .. ..@ Dim     : int [1:2] 13370 12\n",
      "  .. ..@ Dimnames:List of 2\n",
      "  .. .. ..$ : NULL\n",
      "  .. .. ..$ : chr [1:12] \"gender\" \"caste\" \"mathematics_marks\" \"english_marks\" ...\n",
      "  .. ..@ x       : num [1:158037] 1 1 1 1 1 1 1 2 2 2 ...\n",
      "  .. ..@ factors : list()\n",
      " $ label: num [1:13370] 0 0 0 0 0 1 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Re-structure the training data set\n",
    "\n",
    "traindata <- ds[train, inputs]\n",
    "\n",
    "traindata[, c(1:ncol(traindata))] <- sapply(traindata[, c(1:ncol(traindata))], as.numeric) \n",
    "ntrain <- as.matrix(traindata[ , c(1:ncol(traindata))])\n",
    "\n",
    "dtrain <- list()\n",
    "dtrain$data <- Matrix(ntrain, sparse=TRUE)\n",
    "dtrain$label <- as.numeric(as.data.frame(ds[train, target])[[1]]) - 1\n",
    "\n",
    "dtrain %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eXtreme Gradient Boosting \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold) \n",
       "Summary of sample sizes: 10696, 10696, 10696, 10696, 10696 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  eta    max_depth  ROC        Sens       Spec      \n",
       "  1e-04   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-04   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-04   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-04  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-04  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-03   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-03   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-03   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-03  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-03  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-02   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-02   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-02   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-02  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-02  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-01   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-01   4         0.7767530  1.0000000  0.22015504\n",
       "  1e-01   8         0.9871498  0.9995285  0.65581395\n",
       "  1e-01  16         1.0000000  1.0000000  0.96279070\n",
       "  1e-01  32         1.0000000  1.0000000  0.96279070\n",
       "  1e+00   2         0.7065927  1.0000000  0.09457364\n",
       "  1e+00   4         0.9152690  0.9993713  0.36899225\n",
       "  1e+00   8         0.9997807  0.9975639  1.00000000\n",
       "  1e+00  16         1.0000000  1.0000000  1.00000000\n",
       "  1e+00  32         1.0000000  1.0000000  1.00000000\n",
       "\n",
       "Tuning parameter 'nrounds' was held constant at a value of 2\n",
       "Tuning\n",
       "\n",
       "Tuning parameter 'min_child_weight' was held constant at a value of 1\n",
       "\n",
       "Tuning parameter 'subsample' was held constant at a value of 1\n",
       "ROC was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were nrounds = 2, max_depth = 16, eta\n",
       " = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1 and subsample = 1. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    "cv.ctrl <- trainControl(method=\"cv\",                     # specify resampling method to be cross-validation\n",
    "                        number=5,                        # set the number of folds to be 5\n",
    "                        verboseIter=FALSE,               # set to FALSE for not printing a training log\n",
    "                        returnData=FALSE,                # set to FALSE for not saving the data\n",
    "                        returnResamp=\"all\",              # save losses across all models\n",
    "                        classProbs=TRUE,                 # set to TRUE for class probabilities be computed for classification models \n",
    "                        summaryFunction=twoClassSummary, # specify a function AUC to compute performance metrics across resamples\n",
    "                        allowParallel=TRUE)              # use a parallel backend if it is available\n",
    "\n",
    "grid.xgb <- expand.grid(nrounds=2,\n",
    "                        max_depth=2^(1:5),\n",
    "                        eta=1*10^(-4:0),\n",
    "                        min_child_weight=1,\n",
    "                        colsample_bytree=1,\n",
    "                        subsample=1,\n",
    "                        gamma=0)\n",
    "\n",
    "set.seed(45)\n",
    "m.xgb.cv <-train(x=ntrain,\n",
    "                 y=as.data.frame(ds[train, target])[[1]],\n",
    "                 method=\"xgbTree\",\n",
    "                 trControl=cv.ctrl,\n",
    "                 tuneGrid=grid.xgb,\n",
    "                 verbose=TRUE,\n",
    "                 metric=\"ROC\",\n",
    "                 nthread =2)\n",
    "\n",
    "m.xgb.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.000000 \n",
      "[2]\ttrain-error:0.000000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   0.08    0.00    0.06 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 5.9 Kb \n",
       "call:\n",
       "  xgb.train(params = params, data = dtrain, nrounds = nrounds, \n",
       "    watchlist = watchlist, verbose = verbose, print_every_n = print_every_n, \n",
       "    early_stopping_rounds = early_stopping_rounds, maximize = maximize, \n",
       "    save_period = save_period, save_name = save_name, xgb_model = xgb_model, \n",
       "    callbacks = callbacks, max.depth = ..1, eta = ..2, min_child_weight = 1, \n",
       "    colsample_bytree = 1, subsample = 1, gamma = 0, nthread = 2, \n",
       "    objective = \"binary:logistic\")\n",
       "params (as set within xgb.train):\n",
       "  max_depth = \"16\", eta = \"0.1\", min_child_weight = \"1\", colsample_bytree = \"1\", subsample = \"1\", gamma = \"0\", nthread = \"2\", objective = \"binary:logistic\", silent = \"1\"\n",
       "xgb.attributes:\n",
       "  niter\n",
       "callbacks:\n",
       "  cb.print.evaluation(period = print_every_n)\n",
       "  cb.evaluation.log()\n",
       "  cb.save.model(save_period = save_period, save_name = save_name)\n",
       "niter: 2\n",
       "evaluation_log:\n",
       " iter train_error\n",
       "    1           0\n",
       "    2           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: xgboost\n",
    "\n",
    "system.time({\n",
    "  m.xgb <- xgboost(data=dtrain$data, \n",
    "                   label=dtrain$label,\n",
    "                   nround=m.xgb.cv$bestTune[[1]], \n",
    "                   max.depth=m.xgb.cv$bestTune[[2]], \n",
    "                   eta=m.xgb.cv$bestTune[[3]], \n",
    "                   min_child_weight=1,\n",
    "                   colsample_bytree=1,\n",
    "                   subsample=1,\n",
    "                   gamma=0,\n",
    "                   nthread=2, \n",
    "                   objective=\"binary:logistic\")\n",
    "})\n",
    "\n",
    "m.xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature       Gain       Cover  Frequency\n",
      "1: mathematics_marks 0.30998281 0.147120885 0.27397260\n",
      "2:     english_marks 0.21674073 0.320301422 0.16438356\n",
      "3: languages_teacher 0.12209233 0.138141886 0.13698630\n",
      "4:          guardian 0.09762265 0.120764467 0.08219178\n",
      "5:             caste 0.09611334 0.078339736 0.15068493\n",
      "6:            gender 0.08452394 0.003929090 0.08219178\n",
      "7:   science_teacher 0.05576744 0.185562256 0.08219178\n",
      "8:          internet 0.01715675 0.005840258 0.02739726\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature importance\n",
    "\n",
    "importance <- xgb.importance(feature_names=dtrain$data@Dimnames[[2]], \n",
    "                             model=m.xgb)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAXFxcqKio8PDxN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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize feature importance\n",
    "\n",
    "xgb.plot.importance(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTML widgets cannot be represented in plain text (need html)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a boosted tree model\n",
    "\n",
    "xgb.plot.tree(dtrain$data@Dimnames[[2]], model=m.xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ data :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  .. ..@ i       : int [1:67713] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  .. ..@ p       : int [1:13] 0 5730 11460 17190 22920 28650 33860 39063 44793 50523 ...\n",
      "  .. ..@ Dim     : int [1:2] 5730 12\n",
      "  .. ..@ Dimnames:List of 2\n",
      "  .. .. ..$ : NULL\n",
      "  .. .. ..$ : chr [1:12] \"gender\" \"caste\" \"mathematics_marks\" \"english_marks\" ...\n",
      "  .. ..@ x       : num [1:67713] 1 1 1 1 1 1 1 1 1 1 ...\n",
      "  .. ..@ factors : list()\n",
      " $ label: num [1:5730] 0 0 0 0 0 1 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Re-structure the testing data set\n",
    "\n",
    "testdata <- ds[test, inputs]\n",
    "\n",
    "testdata[, c(1:ncol(traindata))] <- sapply(testdata[, c(1:ncol(traindata))], as.numeric) \n",
    "ntest <- as.matrix(testdata[, c(1:ncol(traindata))])\n",
    "\n",
    "dtest <- list()\n",
    "dtest$data <- Matrix(ntest, sparse=TRUE)\n",
    "dtest$label <- as.numeric(as.data.frame(ds[test, target])[[1]]) - 1\n",
    "\n",
    "dtest %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>continue_drop</th><th scope=col>xgboost_prediction</th><th scope=col>xgboost_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.290    </td><td>0.512    </td><td>0.290    </td><td>4        </td><td> 7       </td><td>3        </td><td>2        </td><td>356      </td><td>14       </td><td>1943     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>2        </td><td>0.602    </td><td>0.666    </td><td>0.602    </td><td>4        </td><td> 2       </td><td>3        </td><td>1        </td><td>179      </td><td> 8       </td><td>1955     </td><td>0        </td><td>0        </td><td>0.4060442</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.594    </td><td>0.519    </td><td>0.594    </td><td>4        </td><td> 8       </td><td>3        </td><td>2        </td><td>335      </td><td>43       </td><td>1916     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.461    </td><td>0.524    </td><td>0.461    </td><td>0        </td><td> 3       </td><td>3        </td><td>2        </td><td>469      </td><td>14       </td><td>1905     </td><td>0        </td><td>0        </td><td>0.4060442</td></tr>\n",
       "\t<tr><td>1        </td><td>2        </td><td>0.742    </td><td>0.672    </td><td>0.742    </td><td>3        </td><td>12       </td><td>3        </td><td>2        </td><td>132      </td><td>14       </td><td>1996     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.503    </td><td>0.523    </td><td>0.503    </td><td>9        </td><td> 0       </td><td>1        </td><td>2        </td><td>397      </td><td> 5       </td><td>1950     </td><td>1        </td><td>1        </td><td>0.5898832</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & continue\\_drop & xgboost\\_prediction & xgboost\\_probability\\\\\n",
       "\\hline\n",
       "\t 1         & 1         & 0.290     & 0.512     & 0.290     & 4         &  7        & 3         & 2         & 356       & 14        & 1943      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 2         & 0.602     & 0.666     & 0.602     & 4         &  2        & 3         & 1         & 179       &  8        & 1955      & 0         & 0         & 0.4060442\\\\\n",
       "\t 1         & 1         & 0.594     & 0.519     & 0.594     & 4         &  8        & 3         & 2         & 335       & 43        & 1916      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 1         & 0.461     & 0.524     & 0.461     & 0         &  3        & 3         & 2         & 469       & 14        & 1905      & 0         & 0         & 0.4060442\\\\\n",
       "\t 1         & 2         & 0.742     & 0.672     & 0.742     & 3         & 12        & 3         & 2         & 132       & 14        & 1996      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 1         & 0.503     & 0.523     & 0.503     & 9         &  0        & 1         & 2         & 397       &  5        & 1950      & 1         & 1         & 0.5898832\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | caste | mathematics_marks | english_marks | science_marks | science_teacher | languages_teacher | guardian | internet | total_students | total_toilets | establishment_year | continue_drop | xgboost_prediction | xgboost_probability | \n",
       "|---|---|---|---|---|---|\n",
       "| 1         | 1         | 0.290     | 0.512     | 0.290     | 4         |  7        | 3         | 2         | 356       | 14        | 1943      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 2         | 0.602     | 0.666     | 0.602     | 4         |  2        | 3         | 1         | 179       |  8        | 1955      | 0         | 0         | 0.4060442 | \n",
       "| 1         | 1         | 0.594     | 0.519     | 0.594     | 4         |  8        | 3         | 2         | 335       | 43        | 1916      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 1         | 0.461     | 0.524     | 0.461     | 0         |  3        | 3         | 2         | 469       | 14        | 1905      | 0         | 0         | 0.4060442 | \n",
       "| 1         | 2         | 0.742     | 0.672     | 0.742     | 3         | 12        | 3         | 2         | 132       | 14        | 1996      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 1         | 0.503     | 0.523     | 0.503     | 9         |  0        | 1         | 2         | 397       |  5        | 1950      | 1         | 1         | 0.5898832 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender caste mathematics_marks english_marks science_marks science_teacher\n",
       "1 1      1     0.290             0.512         0.290         4              \n",
       "2 1      2     0.602             0.666         0.602         4              \n",
       "3 1      1     0.594             0.519         0.594         4              \n",
       "4 1      1     0.461             0.524         0.461         0              \n",
       "5 1      2     0.742             0.672         0.742         3              \n",
       "6 1      1     0.503             0.523         0.503         9              \n",
       "  languages_teacher guardian internet total_students total_toilets\n",
       "1  7                3        2        356            14           \n",
       "2  2                3        1        179             8           \n",
       "3  8                3        2        335            43           \n",
       "4  3                3        2        469            14           \n",
       "5 12                3        2        132            14           \n",
       "6  0                1        2        397             5           \n",
       "  establishment_year continue_drop xgboost_prediction xgboost_probability\n",
       "1 1943               0             0                  0.4057302          \n",
       "2 1955               0             0                  0.4060442          \n",
       "3 1916               0             0                  0.4057302          \n",
       "4 1905               0             0                  0.4060442          \n",
       "5 1996               0             0                  0.4057302          \n",
       "6 1950               1             1                  0.5898832          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.xgb, dtest$data)\n",
    "threshold <- 0.5\n",
    "xgboost_probability <- predictions\n",
    "xgboost_prediction <- ifelse(xgboost_probability > threshold, 1, 0)\n",
    "pred <- cbind(testdata, dtest$label, xgboost_prediction, xgboost_probability)\n",
    "names(pred)[names(pred) == \"dtest$label\"] <- target\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5475    0\n",
      "       1    0  255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>1</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 1\n",
       "\\item[Precision] 1\n",
       "\\item[Recall] 1\n",
       "\\item[F-Score] 1\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   1Precision\n",
       ":   1Recall\n",
       ":   1F-Score\n",
       ":   1\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "        1         1         1         1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nkUQCQiSRgBBJJCD/H/XeV140I+uZAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "metrics.xgb <- evaluateModel(data=pred,\n",
    "                             observed=\"continue_drop\",\n",
    "                             predicted=\"xgboost_prediction\")\n",
    "metrics.xgb\n",
    "\n",
    "rocChart(pr=pred$xgboost_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Finish Up - Save Model\n",
    "\n",
    "We save the model, together with the dataset and other variables, into a binary R file. Here, we use xgboost model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'models/studentDropIndia_xgboost_20161220_165404.RData'"
      ],
      "text/latex": [
       "'models/studentDropIndia\\_xgboost\\_20161220\\_165404.RData'"
      ],
      "text/markdown": [
       "'models/studentDropIndia_xgboost_20161220_165404.RData'"
      ],
      "text/plain": [
       "[1] \"models/studentDropIndia_xgboost_20161220_165404.RData\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- m.xgb\n",
    "mtype <- 'xgboost'\n",
    "pr <- xgboost_probability\n",
    "cl <- xgboost_prediction\n",
    "\n",
    "dname <- \"models\"\n",
    "if (! file.exists(dname)) dir.create(dname)\n",
    "time.stamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")\n",
    "fstem <- paste(dsname, mtype, time.stamp, sep=\"_\")\n",
    "(fname <- file.path(dname, sprintf(\"%s.RData\", fstem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(ds, dsname, vars, target, ignore,\n",
    "form, nobs, seed, train, test, model, mtype, pr, cl,\n",
    "file=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load this later and replicate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ds'</li>\n",
       "\t<li>'dsname'</li>\n",
       "\t<li>'vars'</li>\n",
       "\t<li>'target'</li>\n",
       "\t<li>'ignore'</li>\n",
       "\t<li>'form'</li>\n",
       "\t<li>'nobs'</li>\n",
       "\t<li>'seed'</li>\n",
       "\t<li>'train'</li>\n",
       "\t<li>'test'</li>\n",
       "\t<li>'model'</li>\n",
       "\t<li>'mtype'</li>\n",
       "\t<li>'pr'</li>\n",
       "\t<li>'cl'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ds'\n",
       "\\item 'dsname'\n",
       "\\item 'vars'\n",
       "\\item 'target'\n",
       "\\item 'ignore'\n",
       "\\item 'form'\n",
       "\\item 'nobs'\n",
       "\\item 'seed'\n",
       "\\item 'train'\n",
       "\\item 'test'\n",
       "\\item 'model'\n",
       "\\item 'mtype'\n",
       "\\item 'pr'\n",
       "\\item 'cl'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ds'\n",
       "2. 'dsname'\n",
       "3. 'vars'\n",
       "4. 'target'\n",
       "5. 'ignore'\n",
       "6. 'form'\n",
       "7. 'nobs'\n",
       "8. 'seed'\n",
       "9. 'train'\n",
       "10. 'test'\n",
       "11. 'model'\n",
       "12. 'mtype'\n",
       "13. 'pr'\n",
       "14. 'cl'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"ds\"     \"dsname\" \"vars\"   \"target\" \"ignore\" \"form\"   \"nobs\"   \"seed\"  \n",
       " [9] \"train\"  \"test\"   \"model\"  \"mtype\"  \"pr\"     \"cl\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(load(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by using generic variable names we can load different model files and perform common operations on them without changing the names within a script. However, do note that each time we load such a saved model file we overwrite any other variables of the same name."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
